{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel Map on Files\n",
    "------------------------\n",
    "\n",
    "For each of a set of filenames, we parse JSON data contents, load that data into a Pandas DataFrame, and then output the result to another file with a nicer format, HDF5.\n",
    "\n",
    "We find that parsing JSON is slow and so we parallelize the process using the [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module to do this work in multiple processes.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "*  Profile code to find bottleneck\n",
    "*  Use `concurrent.futures` to `map` a function across many inputs in parallel\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "*  Pandas\n",
    "*  concurrent.futures (standard in Python 3, `pip install futures` in Python 2)\n",
    "*  snakeviz (for profile visualization, `pip install snakeviz`)\n",
    "\n",
    "\n",
    "    pip install snakeviz\n",
    "    pip install futures\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "\n",
    "We need to get some data to work with.\n",
    "We are going to generate some [fake stock data](https://github.com/mrocklin/fakestockdata) by adding a bunch of points between real stock data points. This will take a few minutes the first time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished aa\n",
      "Finished bwa\n",
      "Finished aig\n",
      "Finished ebay\n",
      "Finished cost\n",
      "Finished d\n",
      "Finished amgn\n",
      "Finished csco\n",
      "Finished abc\n",
      "Finished emr\n",
      "Finished aapl\n",
      "Finished amzn\n",
      "Finished esrx\n",
      "Finished goog\n",
      "Finished nyx\n",
      "Finished gas\n",
      "Finished met\n",
      "Finished hpq\n",
      "Finished jbl\n",
      "Finished ge\n",
      "Finished hp\n",
      "Finished jpm\n",
      "Finished hal\n",
      "Finished ibm\n",
      "Finished zmh\n",
      "Finished pcg\n",
      "Finished usb\n",
      "Finished vrsn\n",
      "Finished yhoo\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/aa\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/ebay\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/csco\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/abc\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/aapl\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/d\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/aig\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/bwa\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/cost\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/amgn\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/emr\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/amzn\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/esrx\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/hal\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/gas\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/jbl\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/ge\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/goog\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/hpq\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/hp\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/jpm\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/ibm\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/met\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/nyx\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/pcg\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/yhoo\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/vrsn\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/usb\n",
      "Finished JSON: /Users/j35/git/OverviewSciPy2016/parallel_python/data/minute/zmh\n"
     ]
    }
   ],
   "source": [
    "%run prep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will load 29 json files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/json/aa.json',\n",
       " 'data/json/aapl.json',\n",
       " 'data/json/abc.json',\n",
       " 'data/json/aig.json',\n",
       " 'data/json/amgn.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(glob(os.path.join('data', 'json', '*.json')))  # data/json/*.json\n",
    "print(\"Will load {:d} json files\".format(len(filenames)))      # https://pyformat.info/\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading json data into pandas data frame then saving them back into HDF5 file format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/json/aa.json\n",
      "data/json/aapl.json\n",
      "data/json/abc.json\n",
      "data/json/aig.json\n",
      "data/json/amgn.json\n",
      "data/json/amzn.json\n",
      "data/json/bwa.json\n",
      "data/json/cost.json\n",
      "data/json/csco.json\n",
      "data/json/d.json\n",
      "data/json/ebay.json\n",
      "data/json/emr.json\n",
      "data/json/esrx.json\n",
      "data/json/gas.json\n",
      "data/json/ge.json\n",
      "data/json/goog.json\n",
      "data/json/hal.json\n",
      "data/json/hp.json\n",
      "data/json/hpq.json\n",
      "data/json/ibm.json\n",
      "data/json/jbl.json\n",
      "data/json/jpm.json\n",
      "data/json/met.json\n",
      "data/json/nyx.json\n",
      "data/json/pcg.json\n",
      "data/json/usb.json\n",
      "data/json/vrsn.json\n",
      "data/json/yhoo.json\n",
      "data/json/zmh.json\n",
      " \n",
      "*** Profile stats marshalled to file '/var/folders/t8/307ghqxx5djb28nl56mkmx7j90c0xy/T/tmppi4001tf'. \n"
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "\n",
    "for fn in filenames:\n",
    "    print(fn)\n",
    "    with open(fn) as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    out_filename = fn[:-5] + '.h5'\n",
    "    df.to_hdf(out_filename, '/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel Execution\n",
    "--------------------\n",
    "\n",
    "We can process each file independently and in parallel.  To accomplish this we'll transform the body of our for loop into a function and then use the [concurrent.futures.ProcessPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#executor-objects) to apply that function across all of the filenames in parallel using multiple processes.\n",
    "\n",
    "### Before\n",
    "\n",
    "Whenever we have code like the following:\n",
    "\n",
    "```python\n",
    "results = []\n",
    "for x in L:\n",
    "    results.append(f(x))\n",
    "```\n",
    "\n",
    "or the following:\n",
    "\n",
    "```python\n",
    "results = [f(x) for x in L]\n",
    "```\n",
    "\n",
    "or the following:\n",
    "\n",
    "```python\n",
    "results = list(map(f, x))\n",
    "```\n",
    "\n",
    "### After\n",
    "\n",
    "We can instead write it as the following:\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor()\n",
    "\n",
    "results = list(e.map(f, L))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 698 µs, sys: 960 µs, total: 1.66 ms\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Sequential code\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(8):\n",
    "    sleep(1)\n",
    "    results.append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 ms, sys: 33.1 ms, total: 47.8 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Parallel code\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor()\n",
    "\n",
    "def slowinc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "results = list(e.map(slowinc, range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:  Convert JSON data to HDF5 in parallel using `concurrent.futures.Executor.map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 1.04 s, total: 23.7 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Sequential code\n",
    "\n",
    "for fn in filenames:\n",
    "    with open(fn) as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    out_filename = fn[:-5] + '.h5'\n",
    "    df.to_hdf(out_filename, '/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel code\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor()\n",
    "\n",
    "def load_parse_store(fn):\n",
    "    with open(fn) as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    out_filename = fn[:-5] + '.h5'\n",
    "    df.to_hdf(out_filename, '/data')\n",
    "\n",
    "list(e.map(load_parse_store, filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try visualizing your parallel version with `%%snakeviz`. Where does it look like it's spending all its time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History: multiprocessing.Pool\n",
    "--------------------------------\n",
    "\n",
    "Perviously people have done multi-processing computations with the `multiprocessing.Pool` object, which behaves more or less identically.\n",
    "\n",
    "However, today most library designers are coordinating around the `concurrent.futures` interface, so it's wise to move over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 ms, sys: 33.5 ms, total: 51.5 ms\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from multiprocessing import Pool\n",
    "p = Pool()\n",
    "\n",
    "list(p.map(load_parse_store, filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "-----------\n",
    "\n",
    "*  Used `snakeviz` to profile code\n",
    "*  Used `concurrent.futures.ProcessPoolExecutor` for simple parallelism across many files\n",
    "    *  Gained some speed boost (but not as much as expected)\n",
    "    *  Lost ability to diagnose performance within parallel code\n",
    "*  Describing each task as a function call helps use tools like map for parallelism\n",
    "*  Making your tasks fast is often at least as important as parallelizing your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
